Unnamed: 0,authors,aggregationType,Pages,publicationName,description,volume,title,subtypeDescription,citedby_count,PublishedDate
0,S Rohini;Gowtham Ramesh;Anand Nair R,Journal,,Computers and Security,"Malware poses risks by compromising both data integrity and system security. Proactive defense efforts have led to the adoption of malware scoring, allowing analysts to assess the severity and develop countermeasures. These scores indicate the degree of malware maliciousness based on triggered signatures. However, current scoring methods do not precisely depict the true extent of malware's maliciousness. This inaccuracy is attributed to an inadequate assessment of the impact of behaviour corresponding to signatures on both system and network resources. To address this limitation, the paper proposes a novel scoring approach that accurately quantifies the impact of signatures triggered by malware through co-occurrence analysis. The method assesses the ensemble behaviour of signatures across two phases. In the first phase of signature scoring, an impact score quantification algorithm initializes each signature to predefined severity score bands based on the studied severity and frequency. The second phase refines initial scores iteratively, considering mutual information among signatures co-occurring in the malware's execution. Experimental results validate the proposed method's ability to accurately reflect signature maliciousness. This novel scoring method enhances malware analysis platforms in generating more precise scores compared to traditional methods, thereby improving resilience against evolving malware threats in the dynamic cybersecurity landscape.",139,MAGIC: Malware behaviour analysis and impact quantification through signature co-occurrence and regression,Article,0,01-04-2024
1,Sukul M.;Lakshmanan; S. Aswin;Gowtham R.,Conference,787-794,"2022 6th International Conference on Trends in Electronics and Informatics, ICOEI 2022 - Proceedings","Ransomware is a subset of malware that blocks the access of infected computers by encrypting the user files and locking the screen. To restore the computer's functionality and user files, the malware demands a ransom, which must be paid in the form of cryptocurrency within a stipulated period. The deleterious effects caused by ransomware must be detected and addressed promptly. It is often difficult to perceive the metrics and parameters to look for, particularly when conducting experiments with unfamiliar ransomware variants. Traditionally, analysis carried out on these suspicious files can be categorized as static or dynamic based analysis. Static-based signature analysis is tremendously affected because of its nature of generating hard-coded policies or rules. Attackers often attempt to breach them by employing various techniques like code obfuscation, encryption, packaging, etc. While the dynamic analysis provides more insights into the analyzed files. The proposed work observes the behavioral aspects of ransomware and builds a generic model using machine learning techniques to detect the variants of ransomware families. Such threats must be detected early, i.e., before encryption takes place. Early detection, however, is hampered by a lack of sufficient information in the early stages of an attack, which leads to low detection accuracy and a high rate of false alarms. Currently, available solutions assume that there is complete knowledge of the behavior of such attacks at the time of detection, but that is not the case. The same is not true for early detection which takes place during an attack when the data are not fully accessible. Our paper proposes a novel technique to address these limitations called Augmented Bootstrapping and this method analyses the API calls made by the ransomware along with their timestamps. These timestamps indicate the API call sequences, which in turn help in constructing the N-gram model. The names of API calls are concatenated together to generate the bigram, trigram, 4-gram, and 5-gram models. Further, TF-IDF scores will be calculated for each of these N-grams sequences, and a machine learning model will be trained based on these values. The method analyses API call sequences of each of the active applications in the system and confirms the ransomware attack when it matches a malicious call sequence pattern. Our empirical results confirm that the proposed work could detect ransomware attacks with high accuracy and fewer false predictions.",,Automated Dynamic Detection of Ransomware using Augmented Bootstrapping,Conference Paper,3,01-01-2022
2,"Dharan, Nidhin S;Gowtham R.",Book,203-216,Lecture Notes in Networks and Systems,"We are proposing a personalized summarization model, which generates an abstractive summary of a random review based on the preference of a specific user. The summary will account the user�s preference on different aspects present in the review. We put forward a Personalized Key Information Guided Network (PKIGN) that pools both extractive and abstractive methods for summary generation. Specifically, keywords present in the review are extracted which are specific to that user, and these keywords are used as key information representation to guide the process of generating summaries. Additionally, Pointer-Guide�mechanism is employed for obtaining long-term value for decoding. We evaluate our model on a new Trip-Advisor hotel review dataset, comprising of 140,874 reviews from 41,600 users. Combining the results from both human evaluation and quantitative analysis, it is seen that our model achieves better performance than existing models on personalized review summarization in case of hotel reviews.",336,Personalized Abstract Review Summarization Using Personalized Key Information-Guided Network,Conference Paper,0,01-01-2022
3,Johnson Shanoop;Gowtham R.;Nair Anand R.,Book,153-167,Lecture Notes in Networks and Systems,"The growth of malware attacks has been phenomenal in the recent past. The COVID-19 pandemic has contributed to an increase in the dependence of a larger than usual workforce on digital technology. This has forced the anti-malware communities to build better software to mitigate malware attacks by detecting it before they wreak havoc. The key part of protecting a system from a malware attack is to identify whether a given file/software is malicious or not. Ransomware attacks are time-sensitive as they must be stopped before the attack manifests as the damage will be irreversible once the attack reaches a certain stage. Dynamic analysis employs a great many methods to decipher the way ransomware files behave when given a free rein. But, there still exists a risk of exposing the system to malicious code while doing that. Ransomware that can sense the analysis environment will most certainly elude the methods used in dynamic analysis. We propose a static analysis method along with machine learning for classifying the ransomware using opcodes extracted by disassemblers. By selecting the most appropriate feature vectors through the tf-idf feature selection method and tuning the parameters that better represent each class, we can increase the efficiency of the ransomware classification model. The ensemble learning-based model implemented on top of N-gram sequence of static opcode data was found to improve the performance significantly in comparison to RF, SVN, LR, and GBDT models when tested against a dataset consisting of live encrypting ransomware samples that had evasive technique to dodge dynamic malware analysis.",336,Ensemble Model Ransomware Classification: A�Static Analysis-based Approach,Conference Paper,3,01-01-2022
4,Muppavarapu Vamsee; Gowtham Ramesh;Gyrard  Amelie;Noura Mahda,Journal,,Data and Knowledge Engineering,"The Internet of Things (IoT) is one of the rapidly growing technologies with the aim of establishing communication among objects, people, and processes. This rapidly growing technology faces a lot of challenges that hinder its wider adoption, specifically in developing applications that involve heterogeneous domains. Currently, developing such interoperable applications require substantial efforts by the developers to hard code the requirements to ensure the correctness of transferring knowledge. The efforts can be significantly reduced by developing an interoperable platform that ensures seamless communication between heterogeneous IoT devices. W3C Web of Things (WoT) is a significant step towards enabling interoperability between IoT devices by integrating the existing Web ecosystem with �Things�. WoT provides a unified interface over a suitable network protocol facilitating interactions between different IoT protocols. WoT Thing Descriptions (TD) enrich interoperability providing both human and machine readable metadata about a Thing. However, the WoT still falls short in providing semantic interoperability due to insufficient standard vocabularies which can describe different IoT application domains. In this paper, we propose a semantic similarity-based approach to automatically identify and extract the most common concepts from sixteen popular ontologies belonging to smart home and smart building domains. The proposed method helps the developers and researchers to develop a domain ontology with reduced effort. The extracted concepts are evaluated by the domain experts and are found to be sufficient in describing the smart home and smart building domains.",135,Knowledge extraction using semantic similarity of concepts from Web of Things knowledge bases,Article,12,01-09-2021
5,"Gowtham, R.;Sanjay, S. P.;Shandilya, Shishir Kumar;Sountharrajan, S.",Journal,01-Nov,International Journal of Web-Based Learning and Teaching Technologies,"The intelligent personal assistant system is designed to support the individual researchers to enhance their quality of the research through the natural language interface. Specifically, this system automatically provides intrinsic details about the importance of the topic of discussion using the timeline analysis. The results generated by the system help the researchers to understand the preference of the global researchers in the specific research field. This system primarily identifies the core topic of the discussion from the user's presentation. Further, the importance of the topic is calculated based on the research articles published over three decades in the related field. The experimental results confirm that the proposed method accurately identifies whether the research topic the user presented is HOT.",16,A cognitive personal assistant system to enhance the individual-centric research capabilities,Article,0,01-07-2021
6,"Gowtham Ramesh;Menen, Anjali",Journal,,Decision Support Systems,"Ransomware is a type of malware that affects the victim data by modifying, deleting, or blocking their access. In recent years, ransomware attacks have resulted in critical data and financial losses to individuals and industries. These disruptions force the need for developing effective anti-ransomware methods in the research community. However, most of the existing techniques are designed to detect a specific ransomware variant instead of providing a generic solution mainly because of the obfuscation techniques used by ransomware or the use of static analysis methods. In this context, this paper proposes a novel ransomware-detection technique that identifies ransomware attacks by evaluating the current state of a computer system with knowledge of a ransomware attack. The finite-state machine model is used to synthesise the knowledge of the ransomware attack with respect to the victim machine. The proposed method monitors the changes happening in the computer system in terms of utilisation, persistence, and lateral movement of its resources to detect ransomware attacks. The experimental results demonstrate that the proposed method can accurately detect attacks from different ransomware variants with significantly few false predictions.",138,Automated dynamic approach for detecting ransomware using finite-state machine,Article,30,01-11-2020
7,"Ravikumar, Sourav;Vinod, Dayanand;Gowtham Ramesh;Pulari, Sini Raj;Mathi, Senthilkumar",Journal,6291-6298,Journal of Intelligent and Fuzzy Systems,"Human-Elephant Conflict (HEC) and its mitigation have always been a serious conservation issue in India. It occurs mainly due to the encroachment of forests by humans as part of societal development. Consequently, these human settlements are highly affected by the intrusion of wild elephants as they cause extensive crop-raiding, injuries and even death in many cases. HEC is a growing problem in rural areas of India which shares a border with forests and other elephant habitats. Based on the studies, it is very explicit that HEC is an important conservation issue which affects the peaceful co-existence of both humans and elephants near the forest areas. The desirable solution for this problem would be to facilitate co-existence among humans and elephants, but this often fails because of technical difficulties. Hence, this paper presents an end-to-end technological solution to facilitate smoother coexistence of humans and elephants. The proposed work deploys a live video surveillance system along with deep learning strategies to effectively detect the presence of elephants. From the numerical analysis, it is revealed that the post-training accuracy of the deep learning model used in the proposed approach is evaluated at 98.7% and outperforms an an out-of-the-box image detector. The layered approach used in the proposed work improves resource management which is a major bottleneck in real-time deployment scenarios.",38,A layered approach to detect elephants in live surveillance video streams using convolution neural networks,Conference Paper,4,01-01-2020
8,"Raghavi, V.;Gowtham, R.",Conference,1497-1501,"2019 International Conference on Intelligent Computing and Control Systems, ICCS 2019","Building information model (BIM) is a new emergence in the field of Architecture, Engineering and Construction (AEC) industry, which facilitates detailed digital representation of a building. The BIM archetype describes the details of a building in the Industry Foundation Class (IFC), which is a platform-agnostic, open data model developed by buildingSMART. The BIM data model embeds interoperability and querying facility among its principal traits in support of the AEC industry. The building information is also required by domains outside the AEC industry, to develop a wide variety of applications such as smart building and indoor navigation systems. In such cases, the IFC data model falls short in supporting interaction with applications of external domains other than AEC. The proposed work is aimed to perform a study on various efforts undertaken in the integration of BIM model with external domain querying and reasoning systems, to retrieve details from underlying building models.",,AI based semantic extensibility and querying techniques for building information model,Conference Paper,3,01-01-2020
9,"Alampalli Ramu, Nikhil;Bandarupalli, Mohana Sai;Nekkanti, Manoj Sri Surya; Gowtham Ramesh",Book,01-Oct,Lecture Notes on Data Engineering and Communications Technologies,"The past two decades have witnessed the significant proliferation of technologies, which has laid a strong foundation for the scientific research in different fields. However, the changes across every field have also created new challenges related to the management of large chunks of data present in the process of converting, storing, searching and providing the user with relevant data. Extracting and transforming the data from one form to another remains as an important task in the current era. It becomes challenging when we focus on the particular extraction instances. Finding the proper research paper from the huge number of papers that includes navigation through the data is not an easy task. It includes huge amount of time search to provide the user with the most appropriate scientific paper of search. This paper concentrates on the extraction of problem statement from one research paper and will be further used to find the related papers. The use of phrases makes the search to considerably reduce the number of search across the Internet and at the same time, it yields a high performance.",38,Summarization of Research Publications Using Automatic Extraction,Book Chapter,6,15-05-2019
10,"Menen, Anjalee;Gowtham, R.",Journal,28-31,International Journal of Recent Technology and Engineering,"Cyber security protects the system from unauthorized access and destruction of data. The intention is to provide security to the system by blocking attackers. Malware or malicious software is any kind of program which is developed with the aim of doing harm to victim�s data. Viruses, worms, Trojan horses, Ransomware, and spyware are different types of malware. When malicious software enters into the system, it will encrypt the user data, deletes or modifies the data. This type of software also used to steal the user data. Ransomware is one of the types of malware which was developed with the intention of getting money from the victims. When Ransomware starts executing in our system, it will start encrypting, deleting and modifying files. The user will get decryption key only after paying the claimed money. Many have found some solutions for detecting some specific Ransomware. The existing technique includes Static based technique which uses signature analysis which can only detect known Ransomware since it compares the extracted code snippet of the target executable with the database of known malware samples. The existing technique is based on the known input and known output and can only detect known Ransomware samples. In this paper we have proposed an efficient Ransomware detection system based on the analysis of behavior with the help of machine learning technique. In the proposed technique, we analyzed the possible behavior of Ransomware based on the changes to user�s files, addition of registry key, stopping the active processes. Based on this behavior, the decision is made using Machine learning technique.",7,An efficient ransomware detection system,Article,1,01-05-2019
11,"Krishna, N. Kaarthik;Prasanth, M.;Gowtham, R.;Karthic, S.;Mini, K. M.",Conference,23816-23823,Materials Today: Proceedings,"The need for standard construction materials is increasing each day due to the pressure faced by construction sectors for achieving an enhanced growth and sustainable development in construction. These have made the developers go for different materials that can be used as an alternate material in construction. In the present work, natural fibers namely coir and sisal fiber are chosen to improve the properties of the concrete. Plain concrete properties are used as a reference to evaluate the effectiveness of this natural fiber reinforced concrete. The objective of this project is to determine the optimum level of coir fiber content for effective enhancement in ductile properties of concrete and on the usage of sisal fiber in increasing the strength properties of concrete.",5,Enhancement of properties of concrete using natural fibers,Conference Paper,63,01-02-2019
12,"Desul, Sudarsana;Madurai Meenachi, N.;Venkatesh, Thejas;Gunta, Vijitha;Gowtham, R.;Sai Baba, Magapu",Journal,Feb-15,Electronic Library,"Purpose: Ontology of a domain mainly consists of a set of concepts and their semantic relations. It is typically constructed and maintained by using ontology editors with substantial human intervention. It is desirable to perform the task automatically, which has led to the development of ontology learning techniques. One of the main challenges of ontology learning from the text is to identify key concepts from the documents. A wide range of techniques for key concept extraction have been proposed but are having the limitations of low accuracy, poor performance, not so flexible and applicability to a specific domain. The propose of this study is to explore a new method to extract key concepts and to apply them to literature in the nuclear domain. Design/methodology/approach: In this article, a novel method for key concept extraction is proposed and applied to the documents from the nuclear domain. A hybrid approach was used, which includes a combination of domain, syntactic name entity knowledge and statistical based methods. The performance of the developed method has been evaluated from the data obtained using two out of three voting logic from three domain experts by using 120 documents retrieved from SCOPUS database. Findings: The work reported pertains to extracting concepts from the set of selected documents and aids the search for documents relating to given concepts. The results of a case study indicated that the method developed has demonstrated better metrics than Text2Onto and CFinder. The method described has the capability of extracting valid key concepts from a set of candidates with long phrases. Research limitations/implications: The present study is restricted to literature coming out in the English language and applied to the documents from nuclear domain. It has the potential to extend to other domains also. Practical implications: The work carried out in the current study has the potential of leading to updating International Nuclear Information System thesaurus for ontology in the nuclear domain. This can lead to efficient search methods. Originality/value: This work is the first attempt to automatically extract key concepts from the nuclear documents. The proposed approach will address and fix the most of the problems that are existed in the current methods and thereby increase the performance.",37,Method for automatic key concepts extraction: Application to documents in the domain of nuclear reactors,Article,9,01-01-2018
13," Gowtham Ramesh;Mathi, Senthilkumar;Pulari, Sini Raj;Krishnamoorthy, Vidya",Conference,2284-2288,"2017 International Conference on Advances in Computing, Communications and Informatics, ICACCI 2017","Human-elephant conflict is a frontline conservation issue in the world. The loss and fragmentation of elephant's habitat owing to the increased human encroachment leads to a notable conservation issue. It raises the need for a non-invasive and efficient solution for the mitigation of human-elephant conflicts. Consequently, deploying a vision based surveillance method in the real time environment can prove to be significantly useful to provide the warnings well in advance thereby reducing the human elephant conflict. In this paper, a method for the identification of elephant as an object using image processing is proposed. The method dynamically learns from the trained images with different backgrounds, lighting conditions. Further, it classifies the input image based on the features of color and texture. The outcomes demonstrate that the proposed method effectively deals with the detection of elephants in near and far distances, cluttered and occluded environment.",2017-January,An automated vision-based method to detect elephants for mitigation of human-elephant conflicts,Conference Paper,12,01-01-2018
14,"Sripadh, Thota;Gowtham Ramesh",Book,437-446,Lecture Notes in Computational Vision and Biomechanics,"Personalization is an emerging topic in the field of Research paper recommender systems and academic research. It is a technique to creative and efficient user profiles to achieve improved recommendations. Our work proposes a new user model to understand user behavior for personalization. This model initially extracts keywords based on the online behaviour of the user. The subsequent steps include concept extraction and user profile ontology construction to derive inferences and define relationships. The suggested model clearly depicts hierarchical ordering of the user�s long-term and current research interests. Furthermore, the adoption of our model contributes to improvement of recommendations.",28,Personalized research paper recommender system,Book Chapter,5,01-01-2018
15,"Sruthi, M.;Pulari, Sini Raj;Gowtham, Ramesh",Book,55-67,Lecture Notes in Computational Vision and Biomechanics,"Recommender systems have changed its purview from prediction accuracy oriented to finding more relevant and useful recommendations to user. �Usefulness� of items are different in different applications. This paper summarizes the works that have been done in this direction. Personalization, context awareness, multiple objectives of recommendations and evaluation metrics are reviewed in this paper.",28,Comprehensive study on usage of multi objectives in recommender systems,Book Chapter,1,02-12-2017
16,"Ramesh, Gowtham;Selvakumar, Kirubakara;Venugopal, Archana",Journal,1244-1260,Behaviour and Information Technology,"Phishing is a fraudulent scheme to steal a user�s personal and confidential information by masking as a trustworthy entity in the electronic commerce. Phishers lure online users to visit their fake webpages and capture the user�s sensitive financial information. The current anti-phishing technique focuses on determining the legitimacy of the webpages that the user visits, and it alerts users with a phishing label when a webpage is found to have suspicious activity. Most of the times, however, these warnings are ignored by the users as there is no significant information present in the alerts except for the phishing label. The method proposed in this paper addresses the aforementioned lacunae by generating a coherent and complete explanation in the natural language text for the anti-phishing system�s decision. The explanation includes the phishing label along with information to establish why such a decision has been taken. This would, in turn, contribute to the user�s enhanced understanding of the threat and also strengthens the user�s trust in the system. It is quite evident from the pilot evaluation, which involved 50 users, that the proposed methodology significantly improves the user�s understanding of the phishing label and strengthens their trust in the system.",36,Intelligent explanation generation system for phishing webpages by employing an inference system,Article,9,30-11-2017
17,"Ramesh, Gowtham;Gupta, Jithendranath;Gamya, P. G.",Journal,75-84,Journal of Information Security and Applications,"Phishing is the act of stealing personal information from the online users by impersonating as a statutory source in the cyberspace. Phishers often bait online users to visit their forged webpages to acquire users sensitive information. Most of the anti-phishing techniques today, endeavor to identify the legitimacy of the webpages the user visits and warn them with a phishing label when the webpage is a phish. But, these warnings generated by the anti-phishing tools are generic and does not provide any assistance for the users to safely navigate to the legitimate webpages. Any anti-phishing technique will be incomplete and incompetent without having a victimized domain identification in place. The method proposed in this paper addresses this lacuna by automatically identifying the victimized domain (target domain) of every successfully distinguished phishing webpage. This method initially identifies the possible target domains of the webpage by analyzing the feign relationships which exist between the webpage and its associated domains through the in-degree link associations. Further, a novel Target Validation (TVD) algorithm is used to ensure the correctness of the identified target domain which in turn helps in reducing the false target predictions of the system. The legitimacy of the webpage is further confirmed using the identified target domain. The experiment results show that this method is efficient in protecting users from the online identity attacks and also in identifying victimized domain with over 99% accuracy.",35,Identification of phishing webpages and its target domains by analyzing the feign relationship,Article,19,01-08-2017
18,"Venugopal, Archana; Gowtham Ramesh",Journal,16953-16960,International Journal of Applied Engineering Research,"Ontology verbalization is a process of converting the logical content of ontologies represented in the Web Ontology Language (OWL) into human understandable natural languages such as English. But, because of the ambiguous and complex nature of the natural languages, it is not directly suitable for verbalization. Controlled Natural Languages (CNLs) are derived from natural languages by applying restrictions and it can be further used for ontology verbalization and authoring. It helps the non-logicians to easily access the OWL ontologies. There are various controlled natural languages that can be used for both ontology authoring and verbalization. Each of the CNL has its own advantages and disadvantages. They overlap in some of the features, while differs widely in some other. The common goal of all the controlled natural languages is to make the OWL statements and the ontologies easily understandable for the users with little or no formal training. This paper focuses on comparing four predominantly used controlled natural languages such as Attempto Controlled English (ACE), Rabbit, Sydney OWL Syntax (SOS) and OWL Simplified English (OSE) with respect to simplicity, clearness, naturalness, and expressivity.",10,A study on verbalization of OWL axioms using controlled natural language,Article,9,01-01-2015
19,"Gowtham, R.;Krishnamurthi, Ilango",Journal,1051-1068,Cluster Computing,"Phishing is web based criminal activity of making innocent online users to reveal sensitive information into fake web sites. Such fake web sites lead to fraudulent charges against individuals and corporations. Phishers have a lot of methods to design and host phished web pages, so in reality there cannot be a single solution that can help us combat phishing. As technology advances, the phishing techniques being used are also getting advanced and hence it demands the anti-phishing techniques also to be upgraded and the new techniques are to be included along with the existing methods. But most of the anti-phishing techniques today do not satisfy these criteria. In this paper, we propose service oriented three-layer architecture model for detecting and identifying phishing web sites as it overcomes the shortcomings of existing anti-phishing solutions. This model enables us to separate the user interface layer from the anti-phishing components layer. This is done through web service middleware layer, which provides us with the freedom of building our own anti-phishing components layer in an efficient and flexible way, independent of other layers. Anti-phishing components layer provides a set of reusable components to convert webpage into feature vectors using finest heuristic methods and external repositories of information. The feature vectors act as an input to trained support vector machine classifier to generate phishing label which determines whether a webpage is legitimate or a phishing page. This when experimented, displayed the significance and importance of three-layered architecture model along with combination of heuristics in detection of phishing webpage. This results in high accuracy of 99 % with less than 1 % of false positive rate. � 2013 Springer Science+Business Media New York.",17,PhishTackle-a web services architecture for anti-phishing,Article,14,01-02-2014
20,"Gowtham Ramesh;Krishnamurthi, Ilango;Kumar, K. Sampath Sree",Journal,Dec-22,Decision Support Systems,"Phishing is a fraudulent act to acquire sensitive information from unsuspecting users by masking as a trustworthy entity in an electronic commerce. Several mechanisms such as spoofed e-mails, DNS spoofing and chat rooms which contain links to phishing websites are used to trick the victims. Though there are many existing anti-phishing solutions, phishers continue to lure the victims. In this paper, we present a novel approach that not only overcomes many of the difficulties in detecting phishing websites but also identifies the phishing target that is being mimicked. We have proposed an anti-phishing technique that groups the domains from hyperlinks having direct or indirect association with the given suspicious webpage. The domains gathered from the directly associated webpages are compared with the domains gathered from the indirectly associated webpages to arrive at a target domain set. On applying Target Identification (TID) algorithm on this set, we zero-in the target domain. We then perform third-party DNS lookup of the suspicious domain and the target domain and on comparison we identify the legitimacy of the suspicious page. � 2014 Elsevier B.V.",61,An efficacious method for detecting phishing webpages through target domain identification,Article,99,01-01-2014
21,"Gowtham, Ramesh.;Krishnamurthi, Ilango",Journal,23-37,Computers and Security,"Phishing is a web-based criminal act. Phishing sites lure sensitive information from naive online users by camouflaging themselves as trustworthy entities. Phishing is considered an annoying threat in the field of electronic commerce. Due to the short lifespan of phishing webpages and the rapid advancement of phishing techniques, maintaining blacklists, white-lists or employing solely heuristics-based approaches are not particularly effective. The impact of phishing can be largely mitigated by adopting a suitable combination of all these techniques. In this study, the characteristics of legitimate and phishing webpages were investigated in depth, and based on this analysis, we proposed heuristics to extract 15 features from such webpages. These heuristic results were fed as an input to a trained machine learning algorithm to detect phishing sites. Before applying heuristics to the webpages, we used two preliminary screening modules in this system. The first module, the preapproved site identifier, checks webpages against a private white-list maintained by the user, and the second module, the Login Form Finder, classifies webpages as legitimate when there are no login forms present. These modules help to reduce superfluous computation in the system and in addition reducing the rate of false positives without compromising on the false negatives. By using all of these modules, we are able to classify webpages with 99.8% precision and a 0.4% of false positive rate. The experimental results indicate that this method is efficient for protecting users from online identity attacks. � 2013 Elsevier Ltd. All rights reserved.",40,A comprehensive and efficacious architecture for detecting phishing webpages,Article,88,01-01-2014
22,"Prabhu, J.;Malmurugan, N.;Gunasekaran, G.;Gowtham, Ramesh",Conference,373-378,"2nd International Conference on Computer Research and Development, ICCRD 2010","Enterprise Resource Planning (ERP) systems represent a huge market in the commercial arena. Products from suppliers such as SAP, Oracle and more recently, Microsoft, dominate the software market. Testing in these projects is a significant effort but is hardly supported by methods and tools other than those provided by the suppliers themselves. Experience shows that testing in these projects is critical, but often neglected. Recent 'lessons learned'work by the Paul Gerrard indicates that a benefit, risk- and coverage-based test approach could significantly reduce the risk of failures. It is evidence that modified condition/decision coverage (MC/DC) is an effective verification method and can help to detect safety faults despite of its expensive cost. In regression testing, it is quite costly to return all of test cases in test suite because new test cases are added to test suite as the software evolves. Therefore, it is necessary to reduce the test suite to improve test efficiency and save test cost. Many existing test-suite reduction techniques are not effective to reduce MC/DC test suite. This paper proposes a new test-suite reduction technique for MC/DC: a bi-objective model that considers both the coverage degree of test case for test requirements and the capability of test cases to reveal error. Our experiment results show that the technique both reduces the size of test suite and better ensures the effectiveness of test suite to reveal error. � 2010 IEEE.",,Study of ERP test-suite reduction based on modified condition/decision coverage,Conference Paper,4,09-08-2010
